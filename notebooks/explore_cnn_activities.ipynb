{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import font_manager as fm\n",
    "import networks\n",
    "import mne_rsa\n",
    "import editdistance\n",
    "from pilot import utils\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "import os\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(word, rotation=0, size=16, family='dejavu sans', fname=None, noise=0):\n",
    "    # Create figure of exactly 64x64 pixels\n",
    "    dpi = 96.\n",
    "    f = Figure(figsize=(64 / dpi, 64 / dpi), dpi=dpi)\n",
    "    \n",
    "    # Initialize an empty figure\n",
    "    f.clf()\n",
    "    ax = f.add_axes([0, 0, 1, 1])\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Start with a grey background image\n",
    "    background = plt.Rectangle((0, 0), 64, 64, facecolor=(0.5, 0.5, 0.5, 1.0), zorder=0)\n",
    "    ax.add_patch(background)\n",
    "\n",
    "    # Add noise to the image. Note the usage of the alpha parameter to tweak the amount of noise\n",
    "    noise_image = np.random.randn(64, 64)\n",
    "    ax.imshow(noise_image, extent=[0, 1, 0, 1], cmap='gray', alpha=noise, zorder=1)\n",
    "    \n",
    "    # Add the text to the image in the selected font\n",
    "    fontprop = fm.FontProperties(family=family, fname=fname, size=size)\n",
    "    ax.text(0.5, 0.5, word, ha='center', va='center',\n",
    "            rotation=rotation, fontproperties=fontprop, alpha=1 - noise, zorder=2)\n",
    "\n",
    "    # We need the canvas object to get the bitmap data at the end\n",
    "    canvas = FigureCanvasAgg(f)\n",
    "    \n",
    "    # Render the image and create a PIL.Image from the pixel data\n",
    "    canvas.draw()\n",
    "    buffer, (width, height) = canvas.print_to_buffer()\n",
    "    image = np.frombuffer(buffer, np.uint8).reshape((height, width, 4))[:, :, :3]\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    # The preprocessing transform used during training of the model\n",
    "    preproc = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(60),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.2, 0.2, 0.2]),\n",
    "        ])\n",
    "    \n",
    "    # Transform the PIL image to a PyTorch tensor for feeding into the model\n",
    "    image = preproc(image).unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create images with noises and see how CNN model gets activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct images\n",
    "images_noise = []\n",
    "for noise in np.arange(0, 1.0, 0.01):\n",
    "    images_noise.append(make_image(word='odote', noise=noise))\n",
    "images_noise = torch.cat(images_noise, 0)\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(make_grid(images_noise/5 + 0.5, nrow=10).numpy().transpose(1, 2, 0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and feed through the images\n",
    "model_name = 'vgg_first_imagenet64_then_tiny-words_tiny-nontext_tiny-imagenet_w2v'\n",
    "checkpoint = torch.load('../models/%s.pth.tar' % model_name, map_location='cpu')\n",
    "model = networks.vgg_small.from_checkpoint(checkpoint)\n",
    "with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "    feature_outputs, classifier_outputs, semantic_outputs = model.get_layer_activations(images_noise)\n",
    "\n",
    "# calculate DSMs\n",
    "dsms_values = [\n",
    "    mne_rsa.compute_dsm(feature_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[3], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(semantic_outputs[0], metric='correlation'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 7))\n",
    "ticklabels = [0, 67, 99]\n",
    "\n",
    "for i in range(len(dsms_values)):\n",
    "    dsm = dsms_values[i]\n",
    "    ax = axes[i%2, i//2]\n",
    "    if i < len(dsms_values)-1:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    else:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar_ax=axes[1, 4], square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    ax.set_xticks(ticklabels)\n",
    "    ax.set_yticks(ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get RSA with pixel-wise DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSM_pixelwise_noise = mne_rsa.compute_dsm(images_noise, metric='euclidean')\n",
    "mne_rsa.plot_dsms(DSM_pixelwise_noise);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90977318 0.65585081 0.61111817 0.56922876 0.56614159 0.56313362\n",
      " 0.32551818 0.25493415]\n"
     ]
    }
   ],
   "source": [
    "rsa_noise = mne_rsa.rsa(dsms_values, DSM_pixelwise_noise, metric='kendall-tau-a')\n",
    "print(rsa_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Are Noisy Images Classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(classifier_outputs[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the Same Thing for Different Fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_with_fonts(words, fonts, font_size=16):\n",
    "    images = []\n",
    "    \n",
    "    for word in words:\n",
    "        for font in fonts:\n",
    "            fontfamily, fontfile = fonts[font]\n",
    "            image = make_image(word, rotation=0, size=font_size, family=fontfamily, fname=fontfile, noise=0)\n",
    "            images.append(image)\n",
    "          \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = {\n",
    "        'ubuntu mono': [None, '../data/fonts/UbuntuMono-R.ttf'],\n",
    "        'courier': [None, '../data/fonts/courier.ttf'],\n",
    "        'luxi mono regular': [None, '../data/fonts/luximr.ttf'],\n",
    "        'lucida console': [None, '../data/fonts/LucidaConsole-R.ttf'],\n",
    "        'lekton': [None, '../data/fonts/Lekton-Regular.ttf'],\n",
    "        'dejavu sans mono': [None, '../data/fonts/DejaVuSansMono.ttf'],\n",
    "        'times new roman': [None, '../data/fonts/times.ttf'],\n",
    "        'arial': [None, '../data/fonts/arial.ttf'],\n",
    "        'arial black': [None, '../data/fonts/arialbd.ttf'],\n",
    "        'verdana': [None, '../data/fonts/verdana.ttf'],\n",
    "        'comic sans ms': [None, '../data/fonts/comic.ttf'],\n",
    "        'georgia': [None, '../data/fonts/georgia.ttf'],\n",
    "        'liberation serif': [None, '../data/fonts/LiberationSerif-Regular.ttf'],\n",
    "        'impact': [None, '../data/fonts/impact.ttf'],\n",
    "        'roboto condensed': [None, '../data/fonts/Roboto-Light.ttf'],\n",
    "    }\n",
    "images_font = torch.cat(images_with_fonts(['odote'], fonts, font_size=12), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(make_grid(images_font/5 + 0.5, nrow=10).numpy().transpose(1, 2, 0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and feed through the images\n",
    "checkpoint = torch.load('../models/%s.pth.tar' % model_name, map_location='cpu')\n",
    "model = networks.vgg_small.from_checkpoint(checkpoint)\n",
    "with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "    feature_outputs, classifier_outputs, semantic_outputs = model.get_layer_activations(images_font)\n",
    "\n",
    "# calculate DSMs\n",
    "dsms_values = [\n",
    "    mne_rsa.compute_dsm(feature_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[3], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(semantic_outputs[0], metric='correlation'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "ticklabels = []\n",
    "\n",
    "for i in range(len(dsms_values)):\n",
    "    dsm = dsms_values[i]\n",
    "    ax = axes[i%2, i//2]\n",
    "    if i < len(dsms_values)-1:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    else:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    ax.set_xticks(ticklabels)\n",
    "    ax.set_yticks(ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find DSM for the raw images (over different fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSM_pixelwise_font = mne_rsa.compute_dsm(images_font, metric='euclidean')\n",
    "mne_rsa.plot_dsms(DSM_pixelwise_font);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60842491 0.51428571 0.47985348 0.53333333 0.28681319 0.20695971\n",
      " 0.25677656 0.25622711]\n"
     ]
    }
   ],
   "source": [
    "rsa_font = mne_rsa.rsa(dsms_values, DSM_pixelwise_font, metric='kendall-tau-a')\n",
    "print(rsa_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it again, for rotation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations = range(0, 360, 30)\n",
    "\n",
    "words = [\"odote\"]\n",
    "\n",
    "images_rot = []\n",
    "for word in words:\n",
    "    for rot in rotations:\n",
    "        image_rot = make_image(word, rotation=rot, size=12, noise=0)\n",
    "        images_rot.append(image_rot)\n",
    "images_rot = torch.cat(images_rot, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(make_grid(images_rot/5 + 0.5, nrow=10).numpy().transpose(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature layer 00, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 01, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 02, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 03, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 04, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 05, output=torch.Size([12, 64, 60, 60])\n",
      "feature layer 06, output=torch.Size([12, 64, 30, 30])\n",
      "feature layer 07, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 08, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 09, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 10, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 11, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 12, output=torch.Size([12, 128, 30, 30])\n",
      "feature layer 13, output=torch.Size([12, 128, 15, 15])\n",
      "feature layer 14, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 15, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 16, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 17, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 18, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 19, output=torch.Size([12, 256, 15, 15])\n",
      "feature layer 20, output=torch.Size([12, 256, 7, 7])\n",
      "feature layer 21, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 22, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 23, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 24, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 25, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 26, output=torch.Size([12, 512, 7, 7])\n",
      "feature layer 27, output=torch.Size([12, 512, 3, 3])\n",
      "classifier layer 00, output=torch.Size([12, 4096])\n",
      "classifier layer 01, output=torch.Size([12, 4096])\n",
      "classifier layer 02, output=torch.Size([12, 4096])\n",
      "classifier layer 03, output=torch.Size([12, 4096])\n",
      "classifier layer 04, output=torch.Size([12, 4096])\n",
      "classifier layer 05, output=torch.Size([12, 4096])\n",
      "classifier layer 06, output=torch.Size([12, 201])\n",
      "classifier layer 07, output=torch.Size([12, 201])\n",
      "classifier layer 08, output=torch.Size([12, 201])\n",
      "semantic layer 00, output=torch.Size([12, 300])\n"
     ]
    }
   ],
   "source": [
    "# Load the model and feed through the images\n",
    "model_name = 'vgg_first_imagenet64_then_tiny-words_tiny-nontext_tiny-imagenet_w2v'\n",
    "checkpoint = torch.load('../models/%s.pth.tar' % model_name, map_location='cpu')\n",
    "model = networks.vgg_small.from_checkpoint(checkpoint)\n",
    "feature_outputs, classifier_outputs, semantic_outputs = model.get_layer_activations(images_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsms_values = [\n",
    "    mne_rsa.compute_dsm(feature_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[3], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(semantic_outputs[0], metric='correlation'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "ticklabels = []\n",
    "\n",
    "for i in range(len(dsms_values)):\n",
    "    dsm = dsms_values[i]\n",
    "    ax = axes[i%2, i//2]\n",
    "    if i < len(dsms_values)-1:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    else:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    ax.set_xticks(ticklabels)\n",
    "    ax.set_yticks(ticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSM_pixelwise_rot = mne_rsa.compute_dsm(images_rot, metric='euclidean')\n",
    "mne_rsa.plot_dsms(DSM_pixelwise_rot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80885781 0.72027972 0.65780886 0.65874126 0.53659674 0.38181818\n",
      " 0.10862471 0.08438228]\n"
     ]
    }
   ],
   "source": [
    "rsa_rot = mne_rsa.rsa(dsms_values, DSM_pixelwise_rot, metric='kendall-tau-a')\n",
    "print(rsa_rot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lastly, try it for word length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/pilot_data/pilot2/pilot2_epo.fif ...\n",
      "    Read a total of 13 projection items:\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Reading ../data/pilot_data/pilot2\\pilot2_epo-1.fif ...\n",
      "    Read a total of 13 projection items:\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1680 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Adding metadata with 13 columns\n",
      "Created an SSP operator (subspace dimension = 13)\n",
      "13 projection items activated\n",
      "Reading ../data/pilot_data/pilot2/pilot2_epo.fif ...\n",
      "    Read a total of 13 projection items:\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Reading ../data/pilot_data/pilot2\\pilot2_epo-1.fif ...\n",
      "    Read a total of 13 projection items:\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "        generated with autossp-1.0.1 (1 x 306) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...    1000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1680 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Adding metadata with 13 columns\n",
      "Created an SSP operator (subspace dimension = 13)\n",
      "13 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>freq</th>\n",
       "      <th>font</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>rotation</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>filename</th>\n",
       "      <th>question</th>\n",
       "      <th>question_correct</th>\n",
       "      <th>question_filename</th>\n",
       "      <th>event_id</th>\n",
       "      <th>question_asked</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>odote</th>\n",
       "      <td>word</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Comic Sans MS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>word_odote.png</td>\n",
       "      <td>_ _ _ _ j</td>\n",
       "      <td>False</td>\n",
       "      <td>word_odote_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurin</th>\n",
       "      <td>word</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Times New Roman</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>word_nurin.png</td>\n",
       "      <td>_ _ _ _ l</td>\n",
       "      <td>False</td>\n",
       "      <td>word_nurin_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurja</th>\n",
       "      <td>word</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Times New Roman</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>word_nurja.png</td>\n",
       "      <td>_ _ _ _ a</td>\n",
       "      <td>True</td>\n",
       "      <td>word_nurja_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>näkö</th>\n",
       "      <td>word</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Times New Roman</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>word_näkö.png</td>\n",
       "      <td>n _ _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>word_näkö_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>näppy</th>\n",
       "      <td>word</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Impact</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>word_näppy.png</td>\n",
       "      <td>_ _ u _ _</td>\n",
       "      <td>False</td>\n",
       "      <td>word_näppy_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds^^o</th>\n",
       "      <td>symbols</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DejaVu Sans</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symbols_ds^^o.png</td>\n",
       "      <td>_ s _ _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>symbols_ds^^o_question.png</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdoo^</th>\n",
       "      <td>symbols</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DejaVu Sans</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symbols_dsdoo^.png</td>\n",
       "      <td>_ _ _ v _ _</td>\n",
       "      <td>False</td>\n",
       "      <td>symbols_dsdoo^_question.png</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsovsd</th>\n",
       "      <td>symbols</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DejaVu Sans</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>symbols_dsovsd.png</td>\n",
       "      <td>_ _ _ _ _ ^</td>\n",
       "      <td>False</td>\n",
       "      <td>symbols_dsovsd_question.png</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssods</th>\n",
       "      <td>symbols</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DejaVu Sans</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symbols_ssods.png</td>\n",
       "      <td>_ _ _ d _</td>\n",
       "      <td>True</td>\n",
       "      <td>symbols_ssods_question.png</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>^^^os</th>\n",
       "      <td>symbols</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DejaVu Sans</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>symbols_^^^os.png</td>\n",
       "      <td>_ ^ _ _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>symbols_^^^os_question.png</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type    freq             font  fontsize  rotation  noise_level  \\\n",
       "text                                                                        \n",
       "odote      word    20.0    Comic Sans MS      20.0       0.0          0.5   \n",
       "nurin      word  1001.0  Times New Roman      20.0     -15.0          0.5   \n",
       "nurja      word    11.0  Times New Roman      30.0     -15.0          0.5   \n",
       "näkö       word   506.0  Times New Roman      30.0     -15.0          0.5   \n",
       "näppy      word    15.0           Impact      30.0       0.0          0.5   \n",
       "...         ...     ...              ...       ...       ...          ...   \n",
       "ds^^o   symbols     NaN      DejaVu Sans      40.0       0.0          0.5   \n",
       "dsdoo^  symbols     NaN      DejaVu Sans      30.0       0.0          0.5   \n",
       "dsovsd  symbols     NaN      DejaVu Sans      40.0      15.0          0.2   \n",
       "ssods   symbols     NaN      DejaVu Sans      40.0     -15.0          0.5   \n",
       "^^^os   symbols     NaN      DejaVu Sans      20.0      15.0          0.5   \n",
       "\n",
       "                  filename     question  question_correct  \\\n",
       "text                                                        \n",
       "odote       word_odote.png    _ _ _ _ j             False   \n",
       "nurin       word_nurin.png    _ _ _ _ l             False   \n",
       "nurja       word_nurja.png    _ _ _ _ a              True   \n",
       "näkö         word_näkö.png      n _ _ _              True   \n",
       "näppy       word_näppy.png    _ _ u _ _             False   \n",
       "...                    ...          ...               ...   \n",
       "ds^^o    symbols_ds^^o.png    _ s _ _ _              True   \n",
       "dsdoo^  symbols_dsdoo^.png  _ _ _ v _ _             False   \n",
       "dsovsd  symbols_dsovsd.png  _ _ _ _ _ ^             False   \n",
       "ssods    symbols_ssods.png    _ _ _ d _              True   \n",
       "^^^os    symbols_^^^os.png    _ ^ _ _ _              True   \n",
       "\n",
       "                  question_filename  event_id  question_asked    y  \n",
       "text                                                                \n",
       "odote       word_odote_question.png      10.0           False    0  \n",
       "nurin       word_nurin_question.png      10.0           False    1  \n",
       "nurja       word_nurja_question.png      10.0           False    2  \n",
       "näkö         word_näkö_question.png      10.0           False    3  \n",
       "näppy       word_näppy_question.png      10.0            True    4  \n",
       "...                             ...       ...             ...  ...  \n",
       "ds^^o    symbols_ds^^o_question.png      30.0           False  355  \n",
       "dsdoo^  symbols_dsdoo^_question.png      30.0           False  356  \n",
       "dsovsd  symbols_dsovsd_question.png      30.0           False  357  \n",
       "ssods    symbols_ssods_question.png      30.0            True  358  \n",
       "^^^os    symbols_^^^os_question.png      30.0           False  359  \n",
       "\n",
       "[360 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = utils.get_stimulus_info(subject=2, data_path='../data')\n",
    "meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>freq</th>\n",
       "      <th>font</th>\n",
       "      <th>fontsize</th>\n",
       "      <th>rotation</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>filename</th>\n",
       "      <th>question</th>\n",
       "      <th>question_correct</th>\n",
       "      <th>question_filename</th>\n",
       "      <th>event_id</th>\n",
       "      <th>question_asked</th>\n",
       "      <th>y</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tuohus</th>\n",
       "      <td>word</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Comic Sans MS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>word_tuohus.png</td>\n",
       "      <td>_ _ _ u _ _</td>\n",
       "      <td>False</td>\n",
       "      <td>word_tuohus_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>särkyä</th>\n",
       "      <td>word</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Impact</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>word_särkyä.png</td>\n",
       "      <td>j _ _ _ _ _</td>\n",
       "      <td>False</td>\n",
       "      <td>word_särkyä_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syaani</th>\n",
       "      <td>word</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Times New Roman</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>word_syaani.png</td>\n",
       "      <td>s _ _ _ _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>word_syaani_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>113</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suippo</th>\n",
       "      <td>word</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Times New Roman</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>word_suippo.png</td>\n",
       "      <td>_ _ _ p _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>word_suippo_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>111</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoola</th>\n",
       "      <td>word</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Impact</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>word_stoola.png</td>\n",
       "      <td>_ t _ _ _ _</td>\n",
       "      <td>True</td>\n",
       "      <td>word_stoola_question.png</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  freq             font  fontsize  rotation  noise_level  \\\n",
       "text                                                                   \n",
       "tuohus  word   5.0    Comic Sans MS      20.0       0.0         0.20   \n",
       "särkyä  word  94.0           Impact      20.0      15.0         0.50   \n",
       "syaani  word  10.0  Times New Roman      20.0     -15.0         0.50   \n",
       "suippo  word  26.0  Times New Roman      40.0     -15.0         0.35   \n",
       "stoola  word   8.0           Impact      20.0      15.0         0.20   \n",
       "\n",
       "               filename     question  question_correct  \\\n",
       "text                                                     \n",
       "tuohus  word_tuohus.png  _ _ _ u _ _             False   \n",
       "särkyä  word_särkyä.png  j _ _ _ _ _             False   \n",
       "syaani  word_syaani.png  s _ _ _ _ _              True   \n",
       "suippo  word_suippo.png  _ _ _ p _ _              True   \n",
       "stoola  word_stoola.png  _ t _ _ _ _              True   \n",
       "\n",
       "               question_filename  event_id  question_asked    y  length  \n",
       "text                                                                     \n",
       "tuohus  word_tuohus_question.png      10.0           False   90       6  \n",
       "särkyä  word_särkyä_question.png      10.0           False  120       6  \n",
       "syaani  word_syaani_question.png      10.0            True  113       6  \n",
       "suippo  word_suippo_question.png      10.0            True  111       6  \n",
       "stoola  word_stoola_question.png      10.0           False  110       6  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['length'] = meta.index.str.len()\n",
    "meta.query('type==\"word\"').sort_values('length', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_len=[]\n",
    "for word in ['t', 'tu', 'tuo', 'tuoh', 'tuohu', 'tuohus']:\n",
    "    image_len = make_image(word, rotation=0, size=12, noise=0)\n",
    "    images_len.append(image_len)\n",
    "images_len = torch.cat(images_len, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "plt.figure(figsize=(5, 1))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.imshow(make_grid(images_len/5 + 0.5, nrow=6).numpy().transpose(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature layer 00, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 01, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 02, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 03, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 04, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 05, output=torch.Size([6, 64, 60, 60])\n",
      "feature layer 06, output=torch.Size([6, 64, 30, 30])\n",
      "feature layer 07, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 08, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 09, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 10, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 11, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 12, output=torch.Size([6, 128, 30, 30])\n",
      "feature layer 13, output=torch.Size([6, 128, 15, 15])\n",
      "feature layer 14, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 15, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 16, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 17, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 18, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 19, output=torch.Size([6, 256, 15, 15])\n",
      "feature layer 20, output=torch.Size([6, 256, 7, 7])\n",
      "feature layer 21, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 22, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 23, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 24, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 25, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 26, output=torch.Size([6, 512, 7, 7])\n",
      "feature layer 27, output=torch.Size([6, 512, 3, 3])\n",
      "classifier layer 00, output=torch.Size([6, 4096])\n",
      "classifier layer 01, output=torch.Size([6, 4096])\n",
      "classifier layer 02, output=torch.Size([6, 4096])\n",
      "classifier layer 03, output=torch.Size([6, 4096])\n",
      "classifier layer 04, output=torch.Size([6, 4096])\n",
      "classifier layer 05, output=torch.Size([6, 4096])\n",
      "classifier layer 06, output=torch.Size([6, 201])\n",
      "classifier layer 07, output=torch.Size([6, 201])\n",
      "classifier layer 08, output=torch.Size([6, 201])\n",
      "semantic layer 00, output=torch.Size([6, 300])\n"
     ]
    }
   ],
   "source": [
    "# Load the model and feed through the images\n",
    "model_name = 'vgg_first_imagenet64_then_tiny-words_tiny-nontext_tiny-imagenet_w2v'\n",
    "checkpoint = torch.load('../models/%s.pth.tar' % model_name, map_location='cpu')\n",
    "model = networks.vgg_small.from_checkpoint(checkpoint)\n",
    "feature_outputs, classifier_outputs, semantic_outputs = model.get_layer_activations(images_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsms_values = [\n",
    "    mne_rsa.compute_dsm(feature_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(feature_outputs[3], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[0], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[1], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(classifier_outputs[2], metric='correlation'),\n",
    "    mne_rsa.compute_dsm(semantic_outputs[0], metric='correlation'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "ticklabels = []\n",
    "\n",
    "\n",
    "for i in range(len(dsms_values)):\n",
    "    dsm = dsms_values[i]\n",
    "    ax = axes[i%2, i//2]\n",
    "    if i < len(dsms_values)-1:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    else:\n",
    "        sns.heatmap(distance.squareform(dsm), ax=ax, cbar=False, square=True, xticklabels=ticklabels,\n",
    "                   yticklabels=ticklabels)\n",
    "    ax.set_xticks(ticklabels)\n",
    "    ax.set_yticks(ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very interesting, the word length matters in the last layers the most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSM_pixelwise_len = mne_rsa.compute_dsm(images_len, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88571429  0.73333333  0.54285714  0.25714286  0.25714286  0.37142857\n",
      " -0.06666667  0.56190476]\n"
     ]
    }
   ],
   "source": [
    "rsa_len = mne_rsa.rsa(dsms_values, DSM_pixelwise_len, metric='kendall-tau-a')\n",
    "print(rsa_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solid result, but shoudn't RSA result be absolute val?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of RSA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\"conv1\", \"conv2\", \"conv3\", \"conv4\", \"dense1\", \"dense2\", \"lexicon\", \"semantic\"]\n",
    "rsas = [rsa_noise, rsa_font, rsa_rot, rsa_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "(8,)\n",
      "(8,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, sharex=True, sharey=True, figsize=(8, 8))\n",
    "titles = [\"Noise\", \"Font\", \"Rotation\", \"Word Length\"]\n",
    "fig.suptitle(\"RSA analysis\")\n",
    "\n",
    "for i in range(4):\n",
    "    print(rsas[i].shape)\n",
    "    axes[i].bar(x=layers, height=rsas[i])\n",
    "    axes[i].set_title(titles[i], fontdict={'verticalalignment': 'center'}, rotation='vertical', x=-0.125, y=0.5)\n",
    "plt.setp(axes, ylim=(-0.2, 1));\n",
    "plt.savefig(\"rsa_analysis.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9097731813997726, 0.6084249084249084, 0.8088578088578089, 0.8857142857142857)\n",
      "(0.655850809570753, 0.5142857142857142, 0.7202797202797203, 0.7333333333333333)\n",
      "(0.6111181730417939, 0.47985347985347987, 0.6578088578088578, 0.5428571428571428)\n",
      "(0.5692287596106549, 0.5333333333333333, 0.6587412587412588, 0.2571428571428571)\n",
      "(0.5661415937512119, 0.2868131868131868, 0.5365967365967366, 0.2571428571428571)\n",
      "(0.5631336194843974, 0.20695970695970695, 0.38181818181818183, 0.37142857142857144)\n",
      "(0.3255181844715084, 0.25677655677655675, 0.10862470862470862, -0.06666666666666667)\n",
      "(0.2549341464758721, 0.2562271062271062, 0.08438228438228439, 0.5619047619047619)\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 2, sharex=True, sharey=True, figsize=(5, 10))\n",
    "titles = [\"Noise\", \"Font\", \"Rotation\", \"Word Length\"]\n",
    "fig.suptitle(\"RSA analysis\")\n",
    "\n",
    "for i, layer in enumerate(zip(*rsas)):\n",
    "    print(layer)\n",
    "    axes.ravel()[i].bar(x=titles, height=layer)\n",
    "    #axes[i].set_title(titles[i], fontdict={'verticalalignment': 'center'}, rotation='vertical', x=-0.125, y=0.5)\n",
    "plt.setp(axes, ylim=(-0.2, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.90977318, 0.65585081, 0.61111817, 0.56922876, 0.56614159,\n",
       "        0.56313362, 0.32551818, 0.25493415]),\n",
       " array([0.60842491, 0.51428571, 0.47985348, 0.53333333, 0.28681319,\n",
       "        0.20695971, 0.25677656, 0.25622711]),\n",
       " array([0.80885781, 0.72027972, 0.65780886, 0.65874126, 0.53659674,\n",
       "        0.38181818, 0.10862471, 0.08438228]),\n",
       " array([ 0.88571429,  0.73333333,  0.54285714,  0.25714286,  0.25714286,\n",
       "         0.37142857, -0.06666667,  0.56190476])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
