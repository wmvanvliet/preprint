\documentclass[a4paper, 10pt]{vanvliet_paper}
\input{acronyms}
\addbibresource{reading_models.bib}

\draft
\title{A large scale computational model of word recognition and its comparison with MEG data}

\author[1*]{Marijn van Vliet}
\author[1]{Oona Rinkinen}
\author[1]{Takao Shimizu}
\author[2]{Barry Devereux}
\author[1]{Riitta Salmelin}
\affil[1]{Department of Neuroscience and Biomedical Engineering, Aalto University}
\affil[2]{School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast}
\affil[*]{Corresponding author: marijn.vanvliet@aalto.fi}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

What computational steps is the brain performing when it recognizes some lines on a piece of paper as a specific word?
This question has been the focus of a large number of neuroimaging studies that examine brain activity during reading.
Noninvasive measurement techniques such as \gls{EEG}\cite{Grainger2009}, \gls{MEG}\cite{Salmelin2007} and \gls{fMRI}\cite{Price2012} have provided a wealth of information about when and where changes in activity might be expected during various tasks involving orthographic processing\cite{Carreiras2014}.
However, it is rarely straightforward to translate observations of brain activity into a mechanistic understanding of the computational process being performed by the brain\cite{Poeppel2012}.

Computational models facilitate the development of cognitive theories by allowing us to reason about conceptual "box and arrow" ideas in a qualitative and quantitative manner\cite{Barber2007, Price2018}.
However, the predictions made by existing models of reading are not directly comparible to actual neuroimaging data, and it is an often repeated sentiment that there should be more contact between the two\cite{Carreiras2014, Laszlo2012, Laszlo2014, Poeppel2012, Taylor2013}.

In the domain of models of reading in the brain, connectionist models using \gls{PDP}\cite{McClelland2003} and "dual route" approaches\cite{Perry2007} have been shown to account for many observational findings in both healthy volunteers and patients\cite{McLeod2000, McClelland2003, Perry2007}.
Furthermore, \textcite{Laszlo2012} have shown that by summing the activity of the computational units in specific layers of a connectionist model, the resulting time varying signal resembles a well known component, observed in \gls{EEG} and \gls{MEG} studies, known as the N400 potential\cite{Kutas2011}.
This result has later been extended to model more of such components\cite{Laszlo2014}.
However, the signal produced by the model of \textcite{Laszlo2012} cannot be directly compared with neuroimaging data, because the simulated environment was extremely simplified to reduce the complexity of the model, whereas the brain data will by nature reflect the reading process in a realistic setting.
For example, the model operates on 5-letter words with an alphabet of only 3 possible letters.
Nevertheless, they demonstrated how a computational model can both perform a simplified reading task and produce neuroimaging-like data.

Recent advances in deep learning and its software ecosystem are rapidly changing our notion of what is computationally tractable to model\cite{Richards2019}.
\Glspl{CNN} have emerged that perform visual object recognition at a large enough scale to enable a direct comparison between network state and imaging data\cite{Schrimpf2018, Devereux2018, Yamins2016} and consequently our understanding of basic visual processing has increased tremendously\cite{Lindsay2020}.
Since the first stages of reading, namely visual word recognition, can be seen as a specialized form of object recognition, \glspl{CNN} may very well be a suitable tool for increasing the scale of traditional connectionist models of reading.

In this study, we trained a \gls{CNN} with a \textsc{vgg}-11 network architecture\cite{Szegedy2015} to perform visual word recognition on bitmap images of rendered text.
The same set of stimulus images was presented to both the model and human volunteers, so the activation inside the model could be directly compared with the amplitude of \gls{MEG} evoked reponses recorded from the study participants.
Whereas the training set of the model consisted only of images of either valid Finnish words or only visual noise, the stimulus set used in the experiment contained images of valid Finnish words, which were similar to the ones present in the training data for the model, but also images that were not part of its training set, namely consonant strings, symbol strings and pseudowords.
We show how various layers in the model behave similarly to several well studied evoked responses and evaluate this similarity both qualitatively and, for the first time, quantitatively.

\section{Results}
\section{Discussion}
One may ask why the lexicon layer of the model is a one-hot encoded output vector.
This is plainly incompatible with how the brain works.
Some abstract semantical representation, such as word2vec or semantic features would clearly be better candidates.
The reason why the final layer of the model is the way it is, is because this is the point where a hard 90 degree turn needs to be made from orthographical similarity to semantic similarity.

The model used in this study is a standard convolutional design and has many shortcomings as a model of the brain.
Nevertheless, the fact that the model performs well despite these shortcomings shows the power of using deep learning models to implement cognitive theories.

\section{Methods}
\section{Acknowledgements}
We acknowledge the computational resources provided by the Aalto Science-IT project.
This research was funded by the Academy of Finland (grant \#310988 to M.v.V, \#255349, \#256459, \#283071 and \#315553 to R.S.).
% TODO: Barry funding information

\newpage
\printbibliography{}

\end{document}


% Ok, dit gaat echt nergens meer over. Waar wil ik het over hebben?\
%
% Statement over neuroimaging en het modeleren van het proces daar achter.
% Voorbeelden van modellen: McClelland, DRP+, Laszlo & Plaut.
% Die laatste trekt een lijn naar neuroimaging: super cool.
% Deep learning schept nieuwe mogelijkheden: dezelfde stimuli kunnen nu gebruikt worden.
% Coole resultaten wat betreft object recognition.
% Dus in deze studie proberen we een deep learning model van reading te maken.
% En we vergelijken de activatie in het model met MEG activatie tijdens lezen.
